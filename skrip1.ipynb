{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMaqO5TXxpMVHjfTY1c4Gbr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Adellamarsha01/srkripsi/blob/main/skrip1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 213
        },
        "id": "aD-Bs0YTpeFn",
        "outputId": "097faf44-e889-4431-c965-d6901caea759"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "usage: colab_kernel_launcher.py [-h] [--img IMG] [--video VIDEO] [--out OUT]\n",
            "colab_kernel_launcher.py: error: unrecognized arguments: -f /root/.local/share/jupyter/runtime/kernel-c8bf1f8d-46ba-475f-87d9-8bce5af33576.json\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "SystemExit",
          "evalue": "ignored",
          "traceback": [
            "An exception has occurred, use %tb to see the full traceback.\n",
            "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py:3561: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
            "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "import argparse\n",
        "import numpy as np\n",
        "\n",
        "argparser = argparse.ArgumentParser(description='Simple implementation of Yolov3 algorithm in Python, using custom Dataset.')\n",
        "\n",
        "argparser.add_argument('--img', type=str)\n",
        "argparser.add_argument('--video', type=str)\n",
        "argparser.add_argument('--out', type=str)\n",
        "\n",
        "args = argparser.parse_args()\n",
        "\n",
        "confidence, threshold = 0.5, 0.3\n",
        "\n",
        "# Load the Custom class labels, Weights and Config files\n",
        "# Then create the DNN model\n",
        "labelPath = './obj.names'\n",
        "labels = open(labelPath).read().strip().split('\\n')\n",
        "weightsPath = './yolov3-tiny.weights'\n",
        "configPath = './yolov3-tiny.cfg'\n",
        "net = cv2.dnn.readNetFromDarknet(configPath, weightsPath)\n",
        "\n",
        "# Get all layer names\n",
        "# Then get all [yolo] layers\n",
        "layer_names = net.getLayerNames()\n",
        "yolo_layers = []\n",
        "for i in net.getUnconnectedOutLayers():\n",
        "    yolo_layers.append(layer_names[i[0] - 1])\n",
        "\n",
        "def draw_bb(img, boxes, confidences, classids, idxs, labels):\n",
        "    # If detection exists\n",
        "    if len(idxs):\n",
        "        for i in idxs.flatten():\n",
        "            # Get BB coordinates\n",
        "            x, y = boxes[i][0], boxes[i][1]\n",
        "            w, h = boxes[i][2], boxes[i][3]\n",
        "\n",
        "            cv2.rectangle(img, (x,y), (x+w, y+h), (0, 255, 0), 10)\n",
        "            text = \"{}:{:2.5f}\".format(labels[classids[i]], confidences[i])\n",
        "            cv2.putText(img, text, (x, y-10), cv2.FONT_HERSHEY_COMPLEX, 2, (255, 70, 0), 3)\n",
        "\n",
        "    return img\n",
        "\n",
        "    # init lists of detected boxes, confidences, class IDs\n",
        "    boxes, confidences, class_ids = [], [], []\n",
        "\n",
        "def predict(net, layer_names, height, width, img, labels):\n",
        "\n",
        "    # Construct a blob from input\n",
        "    # Then perform a forward pass of the yolo OD\n",
        "    # Then get BB with associated probabilities\n",
        "    blob = cv2.dnn.blobFromImage(img, 1/255.0, (416, 416), swapRB=True, crop=False)\n",
        "    net.setInput(blob)\n",
        "    layerOutputs = net.forward(layer_names)\n",
        "\n",
        "    # init lists of detected boxes, confidences, class IDs\n",
        "    boxes, confidences, class_ids = [], [], []\n",
        "\n",
        "    # loop over each of the layer outputs\n",
        "    for out in layerOutputs:\n",
        "        # loop over each of the detections\n",
        "        for detection in out:\n",
        "            # extract the class ID and confidence of the current OD\n",
        "            scores = detection[5:]\n",
        "            class_id = np.argmax(scores)\n",
        "            detect_confidence = scores[class_id]\n",
        "\n",
        "            # filter out a weal predictions by ensuring the detected\n",
        "            # probability is greater than minimum probability\n",
        "\n",
        "            if detect_confidence > confidence:\n",
        "                # scale the BB coordinates back relative to\n",
        "                # the size of the image.\n",
        "                # YOLO returns the center (x,y) - coordinates of BB\n",
        "                # followed by the boxes weight and height\n",
        "                box = detection[0:4] * np.array([width, height, width, height])\n",
        "                centerX, centerY, box_width, box_height = box.astype('int')\n",
        "\n",
        "                # use the center (x, y) - coordinates to derive\n",
        "                # the top and left corner of the BB\n",
        "                x = int(centerX - (box_width / 2))\n",
        "                y = int(centerY - (box_height / 2))\n",
        "\n",
        "                # update list of BB coordinates, confidences, and class IDs\n",
        "                boxes.append([x, y, int(box_width), int(box_height)])\n",
        "                confidences.append(float(detect_confidence))\n",
        "                class_ids.append(class_id)\n",
        "\n",
        "    # Suppress overlapping boxes\n",
        "    idxs = cv2.dnn.NMSBoxes(boxes, confidences, confidence, threshold)\n",
        "\n",
        "    img = draw_bb(img, boxes, confidences, class_ids, idxs, labels)\n",
        "\n",
        "    return img, boxes, confidences, class_ids, idxs\n",
        "\n",
        "if args.img:\n",
        "    img = cv2.imread(args.img)\n",
        "    height, width = img.shape[:2]\n",
        "    img, _, _, _, _ = predict(net, yolo_layers, height, width, img, labels)\n",
        "\n",
        "    if args.out:\n",
        "        cv2.imwrite(args.out, img)\n",
        "    else:\n",
        "        img = cv2.resize(img, (800, 800))\n",
        "        cv2.imshow('Prediction', img)\n",
        "        cv2.waitKey(0)\n",
        "\n",
        "elif args.video:\n",
        "    cap = cv2.VideoCapture(args.video)\n",
        "    height, width = None, None\n",
        "    writer = None\n",
        "\n",
        "    while True:\n",
        "        grabbed, frame = cap.read()\n",
        "        print(grabbed, frame)\n",
        "        if not grabbed:\n",
        "            break\n",
        "\n",
        "        if width is None or height is None:\n",
        "            height, width = frame.shape[:2]\n",
        "\n",
        "        frame, _, _, _, _ = predict(net, yolo_layers, height, width, frame, labels)\n",
        "\n",
        "        if writer is None:\n",
        "            fourcc = cv2.VideoWriter_fourcc(*\"MJPG\")\n",
        "            writer = cv2.VideoWriter(args.out, fourcc, 60, (frame.shape[1], frame.shape[0]), True)\n",
        "\n",
        "        writer.write(frame)\n",
        "\n",
        "    writer.release()\n",
        "    cap.release()"
      ]
    }
  ]
}